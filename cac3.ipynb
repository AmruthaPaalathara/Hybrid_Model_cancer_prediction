{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name: Amrutha Paalathara\n",
    "#Class: 5 Msc DSA\n",
    "#Register Number: 23122004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Evaluation Metrics:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.89\n",
      "Recall: 0.94\n",
      "F1-Score: 0.91\n",
      "Confusion Matrix:\n",
      "[[101   7]\n",
      " [  4  59]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       108\n",
      "           1       0.89      0.94      0.91        63\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.93      0.94      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('cancerAllv3.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "features = data.drop('diagnosis', axis=1)\n",
    "target = data['diagnosis']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "print(\"Decision Tree Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.2f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class CancerEnv(gym.Env):\n",
    "    def __init__(self, decision_tree, current_conditions):\n",
    "        super(CancerEnv, self).__init__()\n",
    "        self.decision_tree = decision_tree\n",
    "        self.current_conditions = current_conditions\n",
    "        self.action_space = spaces.Discrete(2)  # Actions: 0 = maintain, 1 = override\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(len(current_conditions) - 1,), dtype=np.float32)\n",
    "        self.max_steps = 1  # End episode after one step\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return np.array(list(self.current_conditions.values())[:-1])  # Exclude diagnosis\n",
    "\n",
    "    def step(self, action):\n",
    "        # Prepare input data with feature names\n",
    "        features = list(self.current_conditions.keys())[:-1]\n",
    "        input_data = pd.DataFrame([list(self.current_conditions.values())[:-1]], columns=features)\n",
    "\n",
    "        # Get decision tree prediction\n",
    "        dt_prediction = self.decision_tree.predict(input_data)[0]\n",
    "\n",
    "        # Override or maintain prediction based on action\n",
    "        final_prediction = dt_prediction if action == 0 else (1 - dt_prediction)\n",
    "\n",
    "        # Reward: +1 for correct prediction, -1 for incorrect\n",
    "        reward = 1 if final_prediction == self.current_conditions['diagnosis'] else -1\n",
    "\n",
    "        # Increment step and check if the episode is done\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.max_steps\n",
    "\n",
    "        return np.array(list(self.current_conditions.values())[:-1]), reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function to build the model\n",
    "def build_model(state_size, action_size):\n",
    "    model = Sequential([\n",
    "        Input(shape=(state_size,)),\n",
    "        Dense(24, activation='relu'),\n",
    "        Dense(24, activation='relu'),\n",
    "        Dense(action_size, activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state size based on the features used for prediction\n",
    "state_size = len(features.columns)  # Match the number of features used in the Decision Tree\n",
    "action_size = 2  # Maintain or override\n",
    "\n",
    "# Build the model\n",
    "model = build_model(state_size, action_size)\n",
    "\n",
    "# Training parameters\n",
    "episodes = 50\n",
    "gamma = 0.95\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "\n",
    "# Example conditions to train the RL environment\n",
    "current_conditions = dict(zip(features.columns, X_test.iloc[0]))\n",
    "current_conditions['diagnosis'] = y_test.iloc[0]\n",
    "env = CancerEnv(decision_tree, current_conditions)\n",
    "\n",
    "# Train the RL model\n",
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, (1, model.input_shape[1]))  # Reshape after reset\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Epsilon-greedy action selection\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = np.random.choice(action_size)  # Random action\n",
    "        else:\n",
    "            action = np.argmax(model.predict(state, verbose=0))  # Predicted action\n",
    "\n",
    "        # Take action and observe result\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, (1, model.input_shape[1]))  # Reshape next_state\n",
    "        total_reward += reward\n",
    "        #action = np.argmax(model.predict(state, verbose=0))  # Correctly reshaped state\n",
    "\n",
    "        # Update Q-value\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = reward + gamma * np.max(model.predict(next_state, verbose=0))\n",
    "\n",
    "        target_f = model.predict(state, verbose=0)\n",
    "        target_f[0][action] = target\n",
    "\n",
    "        model.fit(state, target_f, epochs=1, verbose=0)  # Train the model\n",
    "        state = next_state\n",
    "\n",
    "    # Decay epsilon to reduce exploration over time\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    print(f\"Episode {e + 1}/{episodes} - Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"RL model training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model Prediction: No Cancer\n"
     ]
    }
   ],
   "source": [
    "# Define the hybrid model prediction function (evaluation only, no training here)\n",
    "def hybrid_model_prediction(decision_tree, current_conditions, model):\n",
    "    \"\"\"\n",
    "    Predict using a hybrid model combining a Decision Tree and RL-based adjustments.\n",
    "\n",
    "    Args:\n",
    "        decision_tree: Trained Decision Tree model.\n",
    "        current_conditions: Dictionary of current feature values (only features, no 'diagnosis').\n",
    "        model: Trained RL model.\n",
    "\n",
    "    Returns:\n",
    "        str: Final prediction ('Cancer' or 'No Cancer').\n",
    "    \"\"\"\n",
    "    # Prepare the state to match the model's input shape (Features only, excluding 'diagnosis')\n",
    "    required_features = list(features.columns)  # Features used for training\n",
    "    state = np.array([current_conditions[feature] for feature in required_features])\n",
    "    state = np.reshape(state, (1, len(required_features)))  # Reshape to (1, 30)\n",
    "\n",
    "    # Use RL model to determine the best action (exploration/exploitation)\n",
    "    best_action = np.argmax(model.predict(state, verbose=0))\n",
    "\n",
    "    # Convert current_conditions to a DataFrame for Decision Tree prediction\n",
    "    input_data = pd.DataFrame([state[0]], columns=required_features)\n",
    "\n",
    "    # Use Decision Tree prediction if action is 0, otherwise override the prediction\n",
    "    if best_action == 0:\n",
    "        final_prediction = decision_tree.predict(input_data)[0]\n",
    "    else:\n",
    "        final_prediction = 1 - decision_tree.predict(input_data)[0]\n",
    "\n",
    "    # Return the final prediction as a label\n",
    "    return 'Cancer' if final_prediction == 1 else 'No Cancer'\n",
    "\n",
    "\n",
    "# Example evaluation:\n",
    "# Define a test case with feature values (Example: all features set to 0.5)\n",
    "new_conditions = dict(zip(features.columns, [0.5] * len(features.columns)))\n",
    "\n",
    "# Evaluate the hybrid model\n",
    "final_prediction = hybrid_model_prediction(decision_tree, new_conditions, model)\n",
    "print(\"Hybrid Model Prediction:\", final_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reinforcement Learning Model Evaluation Metrics:\n",
      "Accuracy: 0.37\n",
      "Precision: 0.37\n",
      "Recall: 1.00\n",
      "F1-Score: 0.54\n",
      "Confusion Matrix:\n",
      "[[  0 108]\n",
      " [  0  63]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       108\n",
      "           1       0.37      1.00      0.54        63\n",
      "\n",
      "    accuracy                           0.37       171\n",
      "   macro avg       0.18      0.50      0.27       171\n",
      "weighted avg       0.14      0.37      0.20       171\n",
      "\n",
      "\n",
      "Hybrid Model Evaluation Metrics:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.89\n",
      "Recall: 0.94\n",
      "F1-Score: 0.91\n",
      "Confusion Matrix:\n",
      "[[101   7]\n",
      " [  4  59]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       108\n",
      "           1       0.89      0.94      0.91        63\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.93      0.94      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amrut\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amrut\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amrut\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare test data and true labels\n",
    "X_test_data = X_test.to_dict(orient='records')  # Convert test features to list of dictionaries\n",
    "true_labels = y_test.values  # True labels (1 for Cancer, 0 for No Cancer)\n",
    "\n",
    "# Generate predictions using the hybrid model\n",
    "predictions = []\n",
    "\n",
    "for test_case in X_test_data:\n",
    "    prediction = hybrid_model_prediction(decision_tree, test_case, model)\n",
    "    predictions.append(1 if prediction == 'Cancer' else 0)  # Convert 'Cancer' to 1, 'No Cancer' to 0\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "\n",
    "# Evaluate Hybrid Model\n",
    "hybrid_predictions = []\n",
    "for test_case in X_test.to_dict(orient='records'):\n",
    "    prediction = hybrid_model_prediction(decision_tree, test_case, model)\n",
    "    hybrid_predictions.append(1 if prediction == 'Cancer' else 0)\n",
    "\n",
    "# RL Predictions (action-based)\n",
    "rl_predictions = []\n",
    "for test_case in X_test.to_dict(orient='records'):\n",
    "    action = np.argmax(model.predict(np.array(list(test_case.values())).reshape(1, -1), verbose=0))\n",
    "    rl_predictions.append(1 - action)  # Action 0 = maintain, 1 = override\n",
    "\n",
    "# Evaluation Metrics\n",
    "print(\"\\nReinforcement Learning Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rl_predictions):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test, rl_predictions):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, rl_predictions):.2f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, rl_predictions):.2f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, rl_predictions)}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rl_predictions))\n",
    "\n",
    "print(\"\\nHybrid Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, hybrid_predictions):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test, hybrid_predictions):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, hybrid_predictions):.2f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, hybrid_predictions):.2f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, hybrid_predictions)}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, hybrid_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
